{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e9bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       CONVENIENCE       0.70      0.63      0.66      3716\n",
      "  DIGITAL SERVICES       0.64      0.50      0.56      1596\n",
      "         ECOMMERCE       0.63      0.39      0.48      2331\n",
      "     ENTERTAINMENT       0.70      0.60      0.65      3421\n",
      " FINTECH/INSURANCE       0.62      0.37      0.46       314\n",
      "           FITNESS       0.52      0.18      0.27        62\n",
      "          GAMBLING       0.81      0.65      0.72       534\n",
      "         GROCERIES       0.64      0.41      0.50      2909\n",
      "             OTHER       0.65      0.65      0.65      4420\n",
      "          PHARMACY       0.62      0.16      0.26      1355\n",
      "       RESTAURANTS       0.60      0.12      0.20       768\n",
      "            RETAIL       0.70      0.26      0.37       990\n",
      "TRANSPORT/DELIVERY       0.77      0.73      0.75      3848\n",
      "         UTILITIES       0.61      0.40      0.48      3071\n",
      "\n",
      "         micro avg       0.68      0.52      0.59     29335\n",
      "         macro avg       0.66      0.43      0.50     29335\n",
      "      weighted avg       0.67      0.52      0.57     29335\n",
      "       samples avg       0.66      0.53      0.55     29335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "csv_path1 = 'C:/Users/games/OneDrive/Desktop/heybanco/data/heybanco/base_clientes_final.csv'\n",
    "csv_path2 = 'C:/Users/games/OneDrive/Desktop/heybanco/data/heybanco/base_transacciones_final.csv'\n",
    "df_clientes = pd.read_csv(csv_path1, parse_dates=[\"fecha_nacimiento\", \"fecha_alta\"])\n",
    "df_tx = pd.read_csv(csv_path2, parse_dates=[\"fecha\"])\n",
    "\n",
    "# Group comercios into categories\n",
    "def group_merchant(comercio):\n",
    "    comercio = comercio.upper()\n",
    "    if comercio in ['NETFLIX', 'SPOTIFY', 'DISNEY PLUS', 'AMAZON PRIME', 'GOOGLE YOUTUBEPREMIUM', 'CRUNCHYROLL', 'VIX', 'APPLE', 'GOOGLE AMAZON MOBILE', 'AUDIBLE', 'ROKU', 'GOOGLE YOUTUBE']:\n",
    "        return 'ENTERTAINMENT'\n",
    "    elif comercio in ['UBER', 'UBER EATS', 'DIDI', 'DIDI RIDES', 'DIDI FOOD', 'DIDIFOOD', 'METROBUS']:\n",
    "        return 'TRANSPORT/DELIVERY'\n",
    "    elif comercio in ['WALMART', 'SORIANA', 'HEB', 'SUPERCENTER', 'COSTCO', 'SAMS CLUB', 'CHEDRAUI', 'ALSUPER', 'SUPERAMA', 'WAL-MART']:\n",
    "        return 'GROCERIES'\n",
    "    elif comercio in ['CFE', 'TELMEX', 'TELCEL', 'IZZI', 'TOTALPLAY', 'TOTAL PLAY', 'MI ATT', 'ATT', 'AT&T', 'MEGACABLE', 'TELEFONICA', 'CABLEYCOMUN', 'RENTAMOVISTAR']:\n",
    "        return 'UTILITIES'\n",
    "    elif comercio in ['OXXO', '7 ELEVEN', '7ELEVEN', 'OXXO GAS', 'COSTCO GAS']:\n",
    "        return 'CONVENIENCE'\n",
    "    elif comercio in ['FARMACIAS DEL AHORRO', 'FARMACIAS GUADALAJARA', 'FARMACIAS SIMILARES']:\n",
    "        return 'PHARMACY'\n",
    "    elif comercio in ['LIVERPOOL', 'SEARS', 'COPPEL', 'MELIMAS']:\n",
    "        return 'RETAIL'\n",
    "    elif comercio in ['SMARTFIT', 'SMART FIT', 'CRUNCHYROLL']:\n",
    "        return 'FITNESS'\n",
    "    elif comercio in ['CARLS JR', 'STARBUCKS']:\n",
    "        return 'RESTAURANTS'\n",
    "    elif comercio in ['OPENAI', 'GOOGLE', 'ITUNES', 'FACEBOOK', 'ADOBE', 'CANVA', 'MICROSOFT', 'PLAYSTATION NETWORK']:\n",
    "        return 'DIGITAL SERVICES'\n",
    "    elif comercio in ['MERCADO PAGO', 'MERCADOPAGO', 'RAPPI', 'RAPPIPRO', 'SOFT RAPPI']:\n",
    "        return 'ECOMMERCE'\n",
    "    elif comercio in ['ALLIANZ MEXICO', 'KUESKI PAY', 'TOTAL PASS', 'BAE', 'APLAZO', 'APLAZ']:\n",
    "        return 'FINTECH/INSURANCE'\n",
    "    elif comercio in ['UNDOSTRES', 'TULOTERO', 'CALIENTE', 'BET365']:\n",
    "        return 'GAMBLING'\n",
    "    elif comercio in ['ROTOPLAS', 'URBANI', 'SMART']:\n",
    "        return 'OTHER'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "df_tx[\"categoria\"] = df_tx[\"comercio\"].apply(group_merchant)\n",
    "\n",
    "# Weekly features\n",
    "df_tx[\"week\"] = df_tx[\"fecha\"].dt.to_period(\"W\").apply(lambda r: r.start_time)\n",
    "weekly_spend = df_tx.groupby([\"id\", \"week\", \"categoria\"])[\"monto\"].sum().reset_index()\n",
    "weekly_spend_pivot = weekly_spend.pivot_table(index=[\"id\", \"week\"], columns=\"categoria\", values=\"monto\", fill_value=0).reset_index()\n",
    "weekly_spend_pivot = weekly_spend_pivot.sort_values([\"id\", \"week\"])\n",
    "\n",
    "# Create rolling features\n",
    "observation_weeks = 4\n",
    "label_week_gap = 1\n",
    "dfs = []\n",
    "for client_id, group in weekly_spend_pivot.groupby(\"id\"):\n",
    "    group = group.reset_index(drop=True)\n",
    "    for i in range(len(group) - observation_weeks - label_week_gap):\n",
    "        obs = group.iloc[i:i+observation_weeks]\n",
    "        label = group.iloc[i+observation_weeks+label_week_gap-1]\n",
    "\n",
    "        # Basic features\n",
    "        features = obs.drop(columns=[\"id\", \"week\"]).mean().to_dict()\n",
    "\n",
    "        # Additional engineered features\n",
    "        features.update({f\"sum_{col}\": obs[col].sum() for col in obs.columns if col not in [\"id\", \"week\"]})\n",
    "        features.update({f\"max_{col}\": obs[col].max() for col in obs.columns if col not in [\"id\", \"week\"]})\n",
    "        features.update({f\"trend_{col}\": obs[col].iloc[-1] - obs[col].iloc[0] for col in obs.columns if col not in [\"id\", \"week\"]})\n",
    "\n",
    "        features[\"id\"] = client_id\n",
    "        features[\"week\"] = group.iloc[i+observation_weeks-1][\"week\"]\n",
    "\n",
    "        labels = (label.drop([\"id\", \"week\"]) > 0).astype(int)\n",
    "        for cat in labels.index:\n",
    "            features[f\"label_{cat}\"] = labels[cat]\n",
    "\n",
    "        dfs.append(features)\n",
    "\n",
    "df_final = pd.DataFrame(dfs)\n",
    "\n",
    "# Split features/labels\n",
    "label_cols = [c for c in df_final.columns if c.startswith(\"label_\")]\n",
    "X = df_final.drop(columns=label_cols + [\"id\", \"week\"])\n",
    "Y = df_final[label_cols]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline with XGBoost\n",
    "numeric_features = X.columns.tolist()\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), numeric_features)\n",
    "])\n",
    "\n",
    "xgb_model = OneVsRestClassifier(\n",
    "    CalibratedClassifierCV(\n",
    "        XGBClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42\n",
    "        ), method=\"sigmoid\"\n",
    "    )\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", xgb_model)\n",
    "])\n",
    "\n",
    "# Train and evaluate\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=[c.replace(\"label_\", \"\") for c in label_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da0b8f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       CONVENIENCE       0.76      0.42      0.54      3716\n",
      "  DIGITAL SERVICES       0.66      0.10      0.18      1596\n",
      "         ECOMMERCE       0.73      0.19      0.30      2331\n",
      "     ENTERTAINMENT       0.68      0.20      0.30      3421\n",
      " FINTECH/INSURANCE       0.57      0.16      0.25       314\n",
      "           FITNESS       0.44      0.13      0.20        62\n",
      "          GAMBLING       0.85      0.24      0.37       534\n",
      "         GROCERIES       0.68      0.23      0.34      2909\n",
      "             OTHER       0.71      0.32      0.44      4420\n",
      "          PHARMACY       0.56      0.06      0.11      1355\n",
      "       RESTAURANTS       0.61      0.09      0.15       768\n",
      "            RETAIL       0.36      0.01      0.01       990\n",
      "TRANSPORT/DELIVERY       0.83      0.56      0.67      3848\n",
      "         UTILITIES       0.54      0.09      0.15      3071\n",
      "\n",
      "         micro avg       0.73      0.26      0.39     29335\n",
      "         macro avg       0.64      0.20      0.29     29335\n",
      "      weighted avg       0.69      0.26      0.36     29335\n",
      "       samples avg       0.51      0.27      0.33     29335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "csv_path1 = 'C:/Users/games/OneDrive/Desktop/heybanco/data/heybanco/base_clientes_final.csv'\n",
    "csv_path2 = 'C:/Users/games/OneDrive/Desktop/heybanco/data/heybanco/base_transacciones_final.csv'\n",
    "df_clientes = pd.read_csv(csv_path1, parse_dates=[\"fecha_nacimiento\", \"fecha_alta\"])\n",
    "df_tx = pd.read_csv(csv_path2, parse_dates=[\"fecha\"])\n",
    "\n",
    "# Agrupar comercios en categorÃ­as\n",
    "def group_merchant(comercio):\n",
    "    comercio = comercio.upper()\n",
    "    if comercio in ['NETFLIX', 'SPOTIFY', 'DISNEY PLUS', 'AMAZON PRIME', 'GOOGLE YOUTUBEPREMIUM', 'CRUNCHYROLL', 'VIX', 'APPLE', 'GOOGLE AMAZON MOBILE', 'AUDIBLE', 'ROKU', 'GOOGLE YOUTUBE']:\n",
    "        return 'ENTERTAINMENT'\n",
    "    elif comercio in ['UBER', 'UBER EATS', 'DIDI', 'DIDI RIDES', 'DIDI FOOD', 'DIDIFOOD', 'METROBUS']:\n",
    "        return 'TRANSPORT/DELIVERY'\n",
    "    elif comercio in ['WALMART', 'SORIANA', 'HEB', 'SUPERCENTER', 'COSTCO', 'SAMS CLUB', 'CHEDRAUI', 'ALSUPER', 'SUPERAMA', 'WAL-MART']:\n",
    "        return 'GROCERIES'\n",
    "    elif comercio in ['CFE', 'TELMEX', 'TELCEL', 'IZZI', 'TOTALPLAY', 'TOTAL PLAY', 'MI ATT', 'ATT', 'AT&T', 'MEGACABLE', 'TELEFONICA', 'CABLEYCOMUN', 'RENTAMOVISTAR']:\n",
    "        return 'UTILITIES'\n",
    "    elif comercio in ['OXXO', '7 ELEVEN', '7ELEVEN', 'OXXO GAS', 'COSTCO GAS']:\n",
    "        return 'CONVENIENCE'\n",
    "    elif comercio in ['FARMACIAS DEL AHORRO', 'FARMACIAS GUADALAJARA', 'FARMACIAS SIMILARES']:\n",
    "        return 'PHARMACY'\n",
    "    elif comercio in ['LIVERPOOL', 'SEARS', 'COPPEL', 'MELIMAS']:\n",
    "        return 'RETAIL'\n",
    "    elif comercio in ['SMARTFIT', 'SMART FIT', 'CRUNCHYROLL']:\n",
    "        return 'FITNESS'\n",
    "    elif comercio in ['CARLS JR', 'STARBUCKS']:\n",
    "        return 'RESTAURANTS'\n",
    "    elif comercio in ['OPENAI', 'GOOGLE', 'ITUNES', 'FACEBOOK', 'ADOBE', 'CANVA', 'MICROSOFT', 'PLAYSTATION NETWORK']:\n",
    "        return 'DIGITAL SERVICES'\n",
    "    elif comercio in ['MERCADO PAGO', 'MERCADOPAGO', 'RAPPI', 'RAPPIPRO', 'SOFT RAPPI']:\n",
    "        return 'ECOMMERCE'\n",
    "    elif comercio in ['ALLIANZ MEXICO', 'KUESKI PAY', 'TOTAL PASS', 'BAE', 'APLAZO', 'APLAZ']:\n",
    "        return 'FINTECH/INSURANCE'\n",
    "    elif comercio in ['UNDOSTRES', 'TULOTERO', 'CALIENTE', 'BET365']:\n",
    "        return 'GAMBLING'\n",
    "    elif comercio in ['ROTOPLAS', 'URBANI', 'SMART']:\n",
    "        return 'OTHER'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "df_tx[\"categoria\"] = df_tx[\"comercio\"].apply(group_merchant)\n",
    "\n",
    "# Weekly features\n",
    "df_tx[\"week\"] = df_tx[\"fecha\"].dt.to_period(\"W\").apply(lambda r: r.start_time)\n",
    "weekly_spend = df_tx.groupby([\"id\", \"week\", \"categoria\"])[\"monto\"].sum().reset_index()\n",
    "weekly_spend_pivot = weekly_spend.pivot_table(index=[\"id\", \"week\"], columns=\"categoria\", values=\"monto\", fill_value=0).reset_index()\n",
    "weekly_spend_pivot = weekly_spend_pivot.sort_values([\"id\", \"week\"])\n",
    "\n",
    "# Rolling features\n",
    "observation_weeks = 4\n",
    "label_week_gap = 1\n",
    "dfs = []\n",
    "for client_id, group in weekly_spend_pivot.groupby(\"id\"):\n",
    "    group = group.reset_index(drop=True)\n",
    "    for i in range(len(group) - observation_weeks - label_week_gap):\n",
    "        obs = group.iloc[i:i+observation_weeks]\n",
    "        label = group.iloc[i+observation_weeks+label_week_gap-1]\n",
    "\n",
    "        features = obs.drop(columns=[\"id\", \"week\"]).mean().to_dict()\n",
    "        features.update({f\"sum_{col}\": obs[col].sum() for col in obs.columns if col not in [\"id\", \"week\"]})\n",
    "        features.update({f\"max_{col}\": obs[col].max() for col in obs.columns if col not in [\"id\", \"week\"]})\n",
    "        features.update({f\"trend_{col}\": obs[col].iloc[-1] - obs[col].iloc[0] for col in obs.columns if col not in [\"id\", \"week\"]})\n",
    "\n",
    "        features[\"id\"] = client_id\n",
    "        features[\"week\"] = group.iloc[i+observation_weeks-1][\"week\"]\n",
    "\n",
    "        labels = (label.drop([\"id\", \"week\"]) > 0).astype(int)\n",
    "        for cat in labels.index:\n",
    "            features[f\"label_{cat}\"] = labels[cat]\n",
    "\n",
    "        dfs.append(features)\n",
    "\n",
    "df_final = pd.DataFrame(dfs)\n",
    "\n",
    "# Split features and labels\n",
    "label_cols = [c for c in df_final.columns if c.startswith(\"label_\")]\n",
    "X = df_final.drop(columns=label_cols + [\"id\", \"week\"])\n",
    "Y = df_final[label_cols]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_features = X.columns.tolist()\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), numeric_features)\n",
    "])\n",
    "\n",
    "# XGBoost Classifier with calibration\n",
    "xgb_base = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# One-vs-Rest Classifier + CalibratedClassifierCV (sigmoid)\n",
    "classifier = OneVsRestClassifier(\n",
    "    CalibratedClassifierCV( method='sigmoid', cv=3)\n",
    ")\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", classifier)\n",
    "])\n",
    "\n",
    "# Train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Report\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=[c.replace(\"label_\", \"\") for c in label_cols]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
